{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44e5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ma-user/work/Yolov5_for_MindSpore_1.1_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be6925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from mindspore import Tensor\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore import context\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "import mindspore as ms\n",
    "\n",
    "from src.yolo import YOLOV5s\n",
    "from src.logger import get_logger\n",
    "from src.yolo_dataset import create_yolo_dataset\n",
    "from src.config import ConfigYOLOV5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cec03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Redirct:\n",
    "    def __init__(self):\n",
    "        self.content = \"\"\n",
    "\n",
    "    def write(self, content):\n",
    "        self.content += content\n",
    "\n",
    "    def flush(self):\n",
    "        self.content = \"\"\n",
    "\n",
    "\n",
    "class DetectionEngine:\n",
    "    \"\"\"Detection engine.\"\"\"\n",
    "\n",
    "    def __init__(self, args_detection):\n",
    "        self.ignore_threshold = args_detection.ignore_threshold\n",
    "        #self.labels = ['0', '90', '180', '270']\n",
    "        self.labels = ['0', '90', '180', '270', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "                       'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "                       'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "                       'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                       'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "                       'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                       'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "                       'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                       'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "                       'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "        self.num_classes = len(self.labels)\n",
    "        self.results = {}\n",
    "        self.file_path = ''\n",
    "        self.save_prefix = args_detection.outputs_dir\n",
    "        self.ann_file = args_detection.ann_file\n",
    "        self._coco = COCO(self.ann_file)\n",
    "        self._img_ids = list(sorted(self._coco.imgs.keys()))\n",
    "        self.det_boxes = []\n",
    "        self.nms_thresh = args_detection.nms_thresh\n",
    "        self.multi_label = args_detection.multi_label\n",
    "        self.multi_label_thresh = args_detection.multi_label_thresh\n",
    "        # self.coco_catids = self._coco.getCatIds()\n",
    "        #self.coco_catIds = [0, 1, 2, 3]\n",
    "        self.coco_catIds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27,\n",
    "                            28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53,\n",
    "                            54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
    "                            81, 82, 84, 85, 86, 87, 88, 89]    \n",
    "    \n",
    "\n",
    "    def do_nms_for_results(self):\n",
    "        \"\"\"Get result boxes.\"\"\"\n",
    "        # np.save('/opt/disk1/hjc/yolov5_positive_policy/result.npy', self.results)\n",
    "        for img_id in self.results:\n",
    "            for clsi in self.results[img_id]:\n",
    "                dets = self.results[img_id][clsi]\n",
    "                dets = np.array(dets)\n",
    "                keep_index = self._diou_nms(dets, thresh=self.nms_thresh)\n",
    "\n",
    "                keep_box = [{'image_id': int(img_id),\n",
    "                             'category_id': int(clsi),\n",
    "                             'bbox': list(dets[i][:4].astype(float)),\n",
    "                             'score': dets[i][4].astype(float)}\n",
    "                            for i in keep_index]\n",
    "                self.det_boxes.extend(keep_box)\n",
    "\n",
    "    def _nms(self, predicts, threshold):\n",
    "        \"\"\"Calculate NMS.\"\"\"\n",
    "        # convert xywh -> xmin ymin xmax ymax\n",
    "        x1 = predicts[:, 0]\n",
    "        y1 = predicts[:, 1]\n",
    "        x2 = x1 + predicts[:, 2]\n",
    "        y2 = y1 + predicts[:, 3]\n",
    "        scores = predicts[:, 4]\n",
    "\n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        order = scores.argsort()[::-1]\n",
    "\n",
    "        reserved_boxes = []\n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            reserved_boxes.append(i)\n",
    "            max_x1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            max_y1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            min_x2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            min_y2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            intersect_w = np.maximum(0.0, min_x2 - max_x1 + 1)\n",
    "            intersect_h = np.maximum(0.0, min_y2 - max_y1 + 1)\n",
    "            intersect_area = intersect_w * intersect_h\n",
    "            ovr = intersect_area / (areas[i] + areas[order[1:]] - intersect_area)\n",
    "\n",
    "            indexes = np.where(ovr <= threshold)[0]\n",
    "            order = order[indexes + 1]\n",
    "        return reserved_boxes\n",
    "\n",
    "    def _diou_nms(self, dets, thresh=0.5):\n",
    "        \"\"\"\n",
    "        convert xywh -> xmin ymin xmax ymax\n",
    "        \"\"\"\n",
    "        x1 = dets[:, 0]\n",
    "        y1 = dets[:, 1]\n",
    "        x2 = x1 + dets[:, 2]\n",
    "        y2 = y1 + dets[:, 3]\n",
    "        scores = dets[:, 4]\n",
    "        areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        order = scores.argsort()[::-1]\n",
    "        keep = []\n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "            inter = w * h\n",
    "            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "            center_x1 = (x1[i] + x2[i]) / 2\n",
    "            center_x2 = (x1[order[1:]] + x2[order[1:]]) / 2\n",
    "            center_y1 = (y1[i] + y2[i]) / 2\n",
    "            center_y2 = (y1[order[1:]] + y2[order[1:]]) / 2\n",
    "            inter_diag = (center_x2 - center_x1) ** 2 + (center_y2 - center_y1) ** 2\n",
    "            out_max_x = np.maximum(x2[i], x2[order[1:]])\n",
    "            out_max_y = np.maximum(y2[i], y2[order[1:]])\n",
    "            out_min_x = np.minimum(x1[i], x1[order[1:]])\n",
    "            out_min_y = np.minimum(y1[i], y1[order[1:]])\n",
    "            outer_diag = (out_max_x - out_min_x) ** 2 + (out_max_y - out_min_y) ** 2\n",
    "            diou = ovr - inter_diag / outer_diag\n",
    "            diou = np.clip(diou, -1, 1)\n",
    "            inds = np.where(diou <= thresh)[0]\n",
    "            order = order[inds + 1]\n",
    "        return keep\n",
    "\n",
    "    def write_result(self):\n",
    "        \"\"\"Save result to file.\"\"\"\n",
    "        import json\n",
    "        t = datetime.datetime.now().strftime('_%Y_%m_%d_%H_%M_%S')\n",
    "        try:\n",
    "            self.file_path = self.save_prefix + '/predict' + t + '.json'\n",
    "            f = open(self.file_path, 'w')\n",
    "            json.dump(self.det_boxes, f)\n",
    "        except IOError as e:\n",
    "            raise RuntimeError(\"Unable to open json file to dump. What(): {}\".format(str(e)))\n",
    "        else:\n",
    "            f.close()\n",
    "            return self.file_path\n",
    "\n",
    "    def get_eval_result(self):\n",
    "        \"\"\"Get eval result.\"\"\"\n",
    "        coco_gt = COCO(self.ann_file)\n",
    "        coco_dt = coco_gt.loadRes(self.file_path)\n",
    "        coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "        coco_eval.evaluate()\n",
    "        coco_eval.accumulate()\n",
    "        rdct = Redirct()\n",
    "        stdout = sys.stdout\n",
    "        sys.stdout = rdct\n",
    "        coco_eval.summarize()\n",
    "        sys.stdout = stdout\n",
    "        return rdct.content\n",
    "\n",
    "    def detect(self, outputs, batch, image_shape, image_id):\n",
    "        \"\"\"Detect boxes.\"\"\"\n",
    "        outputs_num = len(outputs)\n",
    "        # output [|32, 52, 52, 3, 85| ]\n",
    "        for batch_id in range(batch):\n",
    "            for out_id in range(outputs_num):\n",
    "                # 32, 52, 52, 3, 85\n",
    "                out_item = outputs[out_id]\n",
    "                # 52, 52, 3, 85\n",
    "                out_item_single = out_item[batch_id, :]\n",
    "                # get number of items in one head, [B, gx, gy, anchors, 5+80]\n",
    "                dimensions = out_item_single.shape[:-1]\n",
    "                out_num = 1\n",
    "                for d in dimensions:\n",
    "                    out_num *= d\n",
    "                ori_w, ori_h = image_shape[batch_id]\n",
    "                img_id = int(image_id[batch_id])\n",
    "                x = out_item_single[..., 0] * ori_w\n",
    "                y = out_item_single[..., 1] * ori_h\n",
    "                w = out_item_single[..., 2] * ori_w\n",
    "                h = out_item_single[..., 3] * ori_h\n",
    "\n",
    "                conf = out_item_single[..., 4:5]\n",
    "                cls_emb = out_item_single[..., 5:]\n",
    "                cls_argmax = np.expand_dims(np.argmax(cls_emb, axis=-1), axis=-1)\n",
    "                x = x.reshape(-1)\n",
    "                y = y.reshape(-1)\n",
    "                w = w.reshape(-1)\n",
    "                h = h.reshape(-1)\n",
    "                x_top_left = x - w / 2.\n",
    "                y_top_left = y - h / 2.\n",
    "                cls_emb = cls_emb.reshape(-1, self.num_classes)\n",
    "                if self.multi_label:\n",
    "                    conf = conf.reshape(-1, 1)\n",
    "                    # create all False\n",
    "                    confidence = cls_emb * conf\n",
    "                    flag = cls_emb > self.multi_label_thresh\n",
    "                    flag = flag.nonzero()\n",
    "                    for index in range(len(flag[0])):\n",
    "                        i = flag[0][index]\n",
    "                        j = flag[1][index]\n",
    "                        confi = confidence[i][j]\n",
    "                        if confi < self.ignore_threshold:\n",
    "                            continue\n",
    "                        if img_id not in self.results:\n",
    "                            self.results[img_id] = defaultdict(list)\n",
    "                        x_lefti = max(0, x_top_left[i])\n",
    "                        y_lefti = max(0, y_top_left[i])\n",
    "                        wi = min(w[i], ori_w)\n",
    "                        hi = min(h[i], ori_h)\n",
    "                        clsi = j\n",
    "                        # transform catId to match coco\n",
    "                        coco_clsi = self.coco_catIds[clsi]\n",
    "                        self.results[img_id][coco_clsi].append([x_lefti, y_lefti, wi, hi, confi])\n",
    "                else:\n",
    "                    cls_argmax = np.expand_dims(np.argmax(cls_emb, axis=-1), axis=-1)\n",
    "                    conf = conf.reshape(-1)\n",
    "                    cls_argmax = cls_argmax.reshape(-1)\n",
    "\n",
    "                    # create all False\n",
    "                    flag = np.random.random(cls_emb.shape) > sys.maxsize\n",
    "                    for i in range(flag.shape[0]):\n",
    "                        c = cls_argmax[i]\n",
    "                        flag[i, c] = True\n",
    "                    confidence = cls_emb[flag] * conf\n",
    "\n",
    "                    for x_lefti, y_lefti, wi, hi, confi, clsi in zip(x_top_left, y_top_left, w, h, confidence,\n",
    "                                                                     cls_argmax):\n",
    "                        if confi < self.ignore_threshold:\n",
    "                            continue\n",
    "                        if img_id not in self.results:\n",
    "                            self.results[img_id] = defaultdict(list)\n",
    "                        x_lefti = max(0, x_lefti)\n",
    "                        y_lefti = max(0, y_lefti)\n",
    "                        wi = min(wi, ori_w)\n",
    "                        hi = min(hi, ori_h)\n",
    "                        # transform catId to match coco\n",
    "                        coco_clsi = self.coco_catids[clsi]\n",
    "                        self.results[img_id][coco_clsi].append([x_lefti, y_lefti, wi, hi, confi])\n",
    "\n",
    "\n",
    "def convert_testing_shape(args_testing_shape):\n",
    "    \"\"\"Convert testing shape to list.\"\"\"\n",
    "    testing_shape = [int(args_testing_shape), int(args_testing_shape)]\n",
    "    return testing_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bc3284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 15:53:42,697:INFO:Creating Network....\n",
      "2022-09-20 15:53:43,846:INFO:outputs/2022-09-20_time_10_02_05/ckpt_0/0-49_14900.ckpt\n",
      "2022-09-20 15:53:44,281:INFO:load_model outputs/2022-09-20_time_10_02_05/ckpt_0/0-49_14900.ckpt success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(129210:281473052063184,MainProcess):2022-09-20-15:53:44.283.561 [mindspore/dataset/core/config.py:464] The shared memory is on, multiprocessing performance will be improved. Note: the required shared memory can't exceeds 80% of the available shared memory. You can reduce max_rowsize or reduce num_parallel_workers to reduce shared memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-09-20 15:53:44,296:INFO:testing shape : [640, 640]\n",
      "2022-09-20 15:53:44,297:INFO:total 200 images to eval\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-09-20 15:53:44,310:INFO:Start inference....\n",
      "2022-09-20 15:55:48,691:INFO:Processing... 0.00% \n",
      "2022-09-20 15:56:48,084:INFO:Processing... 4.00% \n",
      "2022-09-20 15:57:47,936:INFO:Processing... 8.00% \n",
      "2022-09-20 15:58:45,707:INFO:Processing... 12.00% \n",
      "2022-09-20 15:59:46,091:INFO:Processing... 16.00% \n",
      "2022-09-20 16:00:46,241:INFO:Processing... 20.00% \n",
      "2022-09-20 16:01:45,359:INFO:Processing... 24.00% \n",
      "2022-09-20 16:02:45,431:INFO:Processing... 28.00% \n",
      "2022-09-20 16:03:46,120:INFO:Processing... 32.00% \n",
      "2022-09-20 16:04:45,284:INFO:Processing... 36.00% \n",
      "2022-09-20 16:05:44,738:INFO:Processing... 40.00% \n",
      "2022-09-20 16:06:42,447:INFO:Processing... 44.00% \n",
      "2022-09-20 16:07:43,409:INFO:Processing... 48.00% \n",
      "2022-09-20 16:08:43,392:INFO:Processing... 52.00% \n",
      "2022-09-20 16:09:41,516:INFO:Processing... 56.00% \n",
      "2022-09-20 16:10:41,897:INFO:Processing... 60.00% \n",
      "2022-09-20 16:11:41,486:INFO:Processing... 64.00% \n",
      "2022-09-20 16:12:42,716:INFO:Processing... 68.00% \n",
      "2022-09-20 16:13:41,225:INFO:Processing... 72.00% \n",
      "2022-09-20 16:14:41,999:INFO:Processing... 76.00% \n",
      "2022-09-20 16:15:41,633:INFO:Processing... 80.00% \n",
      "2022-09-20 16:16:42,902:INFO:Processing... 84.00% \n",
      "2022-09-20 16:17:42,305:INFO:Processing... 88.00% \n",
      "2022-09-20 16:18:41,804:INFO:Processing... 92.00% \n",
      "2022-09-20 16:19:43,928:INFO:Processing... 96.00% \n",
      "2022-09-20 16:19:43,937:INFO:Calculating mAP...\n",
      "2022-09-20 16:19:44,111:INFO:result file path: outputs/2022-09-20_time_15_53_42/predict_2022_09_20_16_19_44.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      "2022-09-20 16:19:44,429:INFO:\n",
      "=============antigen datasets eval reulst=========\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.693\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.689\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.684\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.687\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n",
      "\n",
      "2022-09-20 16:19:44,431:INFO:testing cost time 0.43h\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('mindspore coco testing')\n",
    "\n",
    "# device related\n",
    "parser.add_argument('--device_target', type=str, default='Ascend',\n",
    "                    help='device where the code will be implemented. (Default: Ascend)')\n",
    "\n",
    "# dataset related\n",
    "parser.add_argument('--data_dir', type=str, default='antigen/dev', help='train data dir')\n",
    "parser.add_argument('--per_batch_size', default=8, type=int, help='batch size for per gpu')\n",
    "\n",
    "# network related\n",
    "parser.add_argument('--pretrained', default='outputs/2022-09-20_time_10_02_05/ckpt_0/0-49_14900.ckpt', type=str, help='model_path, local pretrained model to load')\n",
    "\n",
    "# logging related\n",
    "parser.add_argument('--log_path', type=str, default='outputs/', help='checkpoint save location')\n",
    "\n",
    "# detect_related\n",
    "parser.add_argument('--nms_thresh', type=float, default=0.6, help='threshold for NMS')\n",
    "parser.add_argument('--ann_file', type=str, default='', help='path to annotation')\n",
    "parser.add_argument('--testing_shape', type=str, default='', help='shape for test ')\n",
    "parser.add_argument('--ignore_threshold', type=float, default=0.001, help='threshold to throw low quality boxes')\n",
    "parser.add_argument('--multi_label', type=ast.literal_eval, default=True, help='whether to use multi label')\n",
    "parser.add_argument('--multi_label_thresh', type=float, default=0.1, help='threshhold to throw low quality boxes')\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "args.data_root = os.path.join(args.data_dir, 'image')\n",
    "args.ann_file = os.path.join(args.data_dir, 'annotations/train.json')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "device_id = int(os.getenv('DEVICE_ID')) if os.getenv('DEVICE_ID') else 0\n",
    "# device_id = 1\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=args.device_target, device_id=device_id)\n",
    "\n",
    "# logger\n",
    "args.outputs_dir = os.path.join(args.log_path,\n",
    "                                datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n",
    "rank_id = int(os.environ.get('RANK_ID')) if os.environ.get('RANK_ID') else 0\n",
    "args.logger = get_logger(args.outputs_dir, rank_id)\n",
    "\n",
    "context.reset_auto_parallel_context()\n",
    "parallel_mode = ParallelMode.STAND_ALONE\n",
    "context.set_auto_parallel_context(parallel_mode=parallel_mode, gradients_mean=True, device_num=1)\n",
    "\n",
    "args.logger.info('Creating Network....')\n",
    "network = YOLOV5s(is_training=False)\n",
    "\n",
    "args.logger.info(args.pretrained)\n",
    "if os.path.isfile(args.pretrained):\n",
    "    param_dict = load_checkpoint(args.pretrained)\n",
    "    param_dict_new = {}\n",
    "    for key, values in param_dict.items():\n",
    "        if key.startswith('moments.'):\n",
    "            continue\n",
    "        elif key.startswith('yolo_network.'):\n",
    "            param_dict_new[key[13:]] = values\n",
    "        else:\n",
    "            param_dict_new[key] = values\n",
    "    load_param_into_net(network, param_dict_new)\n",
    "    args.logger.info('load_model {} success'.format(args.pretrained))\n",
    "else:\n",
    "    args.logger.info('{} not exists or not a pre-trained file'.format(args.pretrained))\n",
    "    assert FileNotFoundError('{} not exists or not a pre-trained file'.format(args.pretrained))\n",
    "    exit(1)\n",
    "\n",
    "data_root = args.data_root\n",
    "ann_file = args.ann_file\n",
    "\n",
    "config = ConfigYOLOV5()\n",
    "if args.testing_shape:\n",
    "    config.test_img_shape = convert_testing_shape(args.testing_shape)\n",
    "\n",
    "ds, data_size = create_yolo_dataset(data_root, ann_file, is_training=False, batch_size=args.per_batch_size,\n",
    "                                    max_epoch=1, device_num=1, rank=rank_id, shuffle=False,\n",
    "                                    config=config)\n",
    "\n",
    "args.logger.info('testing shape : {}'.format(config.test_img_shape))\n",
    "args.logger.info('total {} images to eval'.format(data_size))\n",
    "\n",
    "network.set_train(False)\n",
    "\n",
    "# init detection engine\n",
    "detection = DetectionEngine(args)\n",
    "\n",
    "input_shape = Tensor(tuple(config.test_img_shape), ms.float32)\n",
    "args.logger.info('Start inference....')\n",
    "for image_index, data in enumerate(ds.create_dict_iterator(num_epochs=1)):\n",
    "    image = data[\"image\"].asnumpy()\n",
    "    image = np.concatenate((image[..., ::2, ::2], image[..., 1::2, ::2],\n",
    "                            image[..., ::2, 1::2], image[..., 1::2, 1::2]), axis=1)\n",
    "    image = Tensor(image)\n",
    "    image_shape_ = data[\"image_shape\"]\n",
    "    image_id_ = data[\"img_id\"]\n",
    "    prediction = network(image, input_shape)\n",
    "    output_big, output_me, output_small = prediction\n",
    "    output_big = output_big.asnumpy()\n",
    "    output_me = output_me.asnumpy()\n",
    "    output_small = output_small.asnumpy()\n",
    "    image_id_ = image_id_.asnumpy()\n",
    "    image_shape_ = image_shape_.asnumpy()\n",
    "    detection.detect([output_small, output_me, output_big], args.per_batch_size, image_shape_, image_id_)\n",
    "    if image_index % 1 == 0:\n",
    "        args.logger.info('Processing... {:.2f}% '.format(image_index * args.per_batch_size / data_size * 100))\n",
    "\n",
    "args.logger.info('Calculating mAP...')\n",
    "detection.do_nms_for_results()\n",
    "result_file_path = detection.write_result()\n",
    "args.logger.info('result file path: {}'.format(result_file_path))\n",
    "eval_result = detection.get_eval_result()\n",
    "\n",
    "cost_time = time.time() - start_time\n",
    "args.logger.info('\\n=============antigen datasets eval reulst=========\\n' + eval_result)\n",
    "args.logger.info('testing cost time {:.2f}h'.format(cost_time / 3600.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc922d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
