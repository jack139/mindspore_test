{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5bfb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ma-user/work/Yolov5_for_MindSpore_1.1_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b6722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import mindspore as ms\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.nn.optim.momentum import Momentum\n",
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindspore.communication.management import init, get_rank, get_group_size\n",
    "from mindspore.train.callback import ModelCheckpoint, RunContext\n",
    "from mindspore.train.callback import _InternalCallbackParam, CheckpointConfig\n",
    "\n",
    "from src.yolo import YOLOV5s, YoloWithLossCell, TrainingWrapper\n",
    "from src.logger import get_logger\n",
    "from src.util import AverageMeter, get_param_groups\n",
    "from src.lr_scheduler import get_lr\n",
    "from src.yolo_dataset import create_yolo_dataset\n",
    "from src.initializer import default_recurisive_init, load_yolov5_params\n",
    "from src.config import ConfigYOLOV5\n",
    "ms.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1863c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(cloud_args=None):\n",
    "    \"\"\"Parse train arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser('mindspore coco training')\n",
    "\n",
    "    # device related\n",
    "    parser.add_argument('--device_target', type=str, default='Ascend',\n",
    "                        help='device where the code will be implemented.')\n",
    "\n",
    "    # dataset related\n",
    "    parser.add_argument('--data_dir', default='antigen', type=str, help='Train dataset directory.')\n",
    "    parser.add_argument('--per_batch_size', default=64, type=int, help='Batch size for Training. Default: 8')\n",
    "\n",
    "    # network related\n",
    "    parser.add_argument('--pretrained_backbone', default='', type=str,\n",
    "                        help='The backbone file of YOLOv5. Default: \"\".')\n",
    "    parser.add_argument('--resume_yolov5', default='', type=str,\n",
    "                        help='The ckpt file of YOLOv5, which used to fine tune. Default: \"\"')\n",
    "\n",
    "    # optimizer and lr related\n",
    "    parser.add_argument('--lr_scheduler', default='cosine_annealing', type=str,\n",
    "                        help='Learning rate scheduler, options: exponential, cosine_annealing. Default: exponential')\n",
    "    parser.add_argument('--lr', default=0.001, type=float, help='Learning rate. Default: 0.01')\n",
    "    parser.add_argument('--lr_epochs', type=str, default='120,150',\n",
    "                        help='Epoch of changing of lr changing, split with \",\". Default: 220,250')\n",
    "    parser.add_argument('--lr_gamma', type=float, default=0.1,\n",
    "                        help='Decrease lr by a factor of exponential lr_scheduler. Default: 0.1')\n",
    "    parser.add_argument('--eta_min', type=float, default=0., help='Eta_min in cosine_annealing scheduler. Default: 0')\n",
    "    parser.add_argument('--T_max', type=int, default=200, help='T-max in cosine_annealing scheduler. Default: 320')\n",
    "    parser.add_argument('--max_epoch', type=int, default=200, help='Max epoch num to train the model. Default: 320')\n",
    "    parser.add_argument('--warmup_epochs', default=1, type=float, help='Warmup epochs. Default: 0')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0005, help='Weight decay factor. Default: 0.0005')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='Momentum. Default: 0.9')\n",
    "\n",
    "    # loss related\n",
    "    parser.add_argument('--loss_scale', type=int, default=1024, help='Static loss scale. Default: 1024')\n",
    "    parser.add_argument('--label_smooth', type=int, default=0, help='Whether to use label smooth in CE. Default:0')\n",
    "    parser.add_argument('--label_smooth_factor', type=float, default=0.1,\n",
    "                        help='Smooth strength of original one-hot. Default: 0.1')\n",
    "\n",
    "    # logging related\n",
    "    parser.add_argument('--log_interval', type=int, default=100, help='Logging interval steps. Default: 100')\n",
    "    parser.add_argument('--ckpt_path', type=str, default='outputs/', help='Checkpoint save location. Default: outputs/')\n",
    "    parser.add_argument('--ckpt_interval', type=int, default=100, help='Save checkpoint interval. Default: 10')\n",
    "\n",
    "    parser.add_argument('--is_save_on_master', type=int, default=1,\n",
    "                        help='Save ckpt on master or all rank, 1 for master, 0 for all ranks. Default: 1')\n",
    "\n",
    "    # distributed related\n",
    "    parser.add_argument('--is_distributed', type=int, default=1,\n",
    "                        help='Distribute train or not, 1 for yes, 0 for no. Default: 1')\n",
    "    parser.add_argument('--rank', type=int, default=0, help='Local rank of distributed. Default: 0')\n",
    "    parser.add_argument('--group_size', type=int, default=1, help='World size of device. Default: 1')\n",
    "\n",
    "    # roma obs\n",
    "    parser.add_argument('--train_url', type=str, default=\"\", help='train url')\n",
    "    # profiler init\n",
    "    parser.add_argument('--need_profiler', type=int, default=0,\n",
    "                        help='Whether use profiler. 0 for no, 1 for yes. Default: 0')\n",
    "\n",
    "    # reset default config\n",
    "    parser.add_argument('--training_shape', type=str, default=\"\", help='Fix training shape. Default: \"\"')\n",
    "    parser.add_argument('--resize_rate', type=int, default=10,\n",
    "                        help='Resize rate for multi-scale training. Default: None')\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    args = merge_args(args, cloud_args)\n",
    "    if args.lr_scheduler == 'cosine_annealing' and args.max_epoch > args.T_max:\n",
    "        args.T_max = args.max_epoch\n",
    "\n",
    "    args.lr_epochs = list(map(int, args.lr_epochs.split(',')))\n",
    "    args.data_root = os.path.join(args.data_dir, 'train')\n",
    "    args.annFile = os.path.join(args.data_dir, 'annotations/train.json')\n",
    "\n",
    "    devid = int(os.getenv('DEVICE_ID', '0'))\n",
    "    context.set_context(mode=context.GRAPH_MODE, enable_auto_mixed_precision=True,\n",
    "                        device_target=args.device_target, save_graphs=False)#, device_id=devid)\n",
    "    # init distributed\n",
    "    if args.is_distributed:\n",
    "        if args.device_target == \"Ascend\":\n",
    "            init()\n",
    "        else:\n",
    "            init(\"nccl\")\n",
    "        args.rank = get_rank()\n",
    "        args.group_size = get_group_size()\n",
    "\n",
    "    # select for master rank save ckpt or all rank save, compatible for model parallel\n",
    "    args.rank_save_ckpt_flag = 0\n",
    "    if args.is_save_on_master:\n",
    "        if args.rank == 0:\n",
    "            args.rank_save_ckpt_flag = 1\n",
    "    else:\n",
    "        args.rank_save_ckpt_flag = 1\n",
    "\n",
    "    # logger\n",
    "    args.outputs_dir = os.path.join(args.ckpt_path,\n",
    "                                    datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n",
    "    args.logger = get_logger(args.outputs_dir, args.rank)\n",
    "    args.logger.save_args(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "def merge_args(args, cloud_args):\n",
    "    args_dict = vars(args)\n",
    "    if isinstance(cloud_args, dict):\n",
    "        for key in cloud_args.keys():\n",
    "            val = cloud_args[key]\n",
    "            if key in args_dict and val:\n",
    "                arg_type = type(args_dict[key])\n",
    "                if arg_type is not type(None):\n",
    "                    val = arg_type(val)\n",
    "                args_dict[key] = val\n",
    "    return args\n",
    "\n",
    "\n",
    "def convert_training_shape(args_training_shape):\n",
    "    training_shape = [int(args_training_shape), int(args_training_shape)]\n",
    "    return training_shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94452b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281473627510224,MainProcess):2022-09-20-10:02:05.297.749 [mindspore/context.py:768]  'enable_auto_mixed_precision' parameters will be deprecated.For details, please see the interface parameter API comments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 10:02:05,810:INFO:Args:\n",
      "2022-09-20 10:02:05,812:INFO:--> device_target: Ascend\n",
      "2022-09-20 10:02:05,812:INFO:--> data_dir: antigen\n",
      "2022-09-20 10:02:05,813:INFO:--> per_batch_size: 64\n",
      "2022-09-20 10:02:05,814:INFO:--> pretrained_backbone: \n",
      "2022-09-20 10:02:05,815:INFO:--> resume_yolov5: \n",
      "2022-09-20 10:02:05,815:INFO:--> lr_scheduler: cosine_annealing\n",
      "2022-09-20 10:02:05,816:INFO:--> lr: 0.001\n",
      "2022-09-20 10:02:05,817:INFO:--> lr_epochs: [120, 150]\n",
      "2022-09-20 10:02:05,818:INFO:--> lr_gamma: 0.1\n",
      "2022-09-20 10:02:05,819:INFO:--> eta_min: 0.0\n",
      "2022-09-20 10:02:05,820:INFO:--> T_max: 200\n",
      "2022-09-20 10:02:05,821:INFO:--> max_epoch: 200\n",
      "2022-09-20 10:02:05,821:INFO:--> warmup_epochs: 1\n",
      "2022-09-20 10:02:05,822:INFO:--> weight_decay: 0.0005\n",
      "2022-09-20 10:02:05,823:INFO:--> momentum: 0.9\n",
      "2022-09-20 10:02:05,824:INFO:--> loss_scale: 1024\n",
      "2022-09-20 10:02:05,825:INFO:--> label_smooth: 0\n",
      "2022-09-20 10:02:05,825:INFO:--> label_smooth_factor: 0.1\n",
      "2022-09-20 10:02:05,826:INFO:--> log_interval: 100\n",
      "2022-09-20 10:02:05,827:INFO:--> ckpt_path: outputs/\n",
      "2022-09-20 10:02:05,828:INFO:--> ckpt_interval: 100\n",
      "2022-09-20 10:02:05,829:INFO:--> is_save_on_master: 1\n",
      "2022-09-20 10:02:05,830:INFO:--> is_distributed: 1\n",
      "2022-09-20 10:02:05,830:INFO:--> rank: 0\n",
      "2022-09-20 10:02:05,831:INFO:--> group_size: 1\n",
      "2022-09-20 10:02:05,832:INFO:--> train_url: \n",
      "2022-09-20 10:02:05,833:INFO:--> need_profiler: 0\n",
      "2022-09-20 10:02:05,834:INFO:--> training_shape: \n",
      "2022-09-20 10:02:05,834:INFO:--> resize_rate: 10\n",
      "2022-09-20 10:02:05,835:INFO:--> data_root: antigen/train\n",
      "2022-09-20 10:02:05,836:INFO:--> annFile: antigen/annotations/train.json\n",
      "2022-09-20 10:02:05,837:INFO:--> rank_save_ckpt_flag: 1\n",
      "2022-09-20 10:02:05,838:INFO:--> outputs_dir: outputs/2022-09-20_time_10_02_05\n",
      "2022-09-20 10:02:05,839:INFO:--> logger: <LOGGER YOLOV5 (NOTSET)>\n",
      "2022-09-20 10:02:05,839:INFO:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281473627510224,MainProcess):2022-09-20-10:02:06.818.100 [mindspore/dataset/core/config.py:464] The shared memory is on, multiprocessing performance will be improved. Note: the required shared memory can't exceeds 80% of the available shared memory. You can reduce max_rowsize or reduce num_parallel_workers to reduce shared memory usage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.57s)\n",
      "creating index...\n",
      "index created!\n",
      "2022-09-20 10:02:10,413:INFO:Finish loading dataset\n",
      "2022-09-20 10:04:53,896:INFO:epoch[0], iter[0], loss:6831.011719, fps:0.39 imgs/sec, lr:3.2258064948109677e-06\n",
      "2022-09-20 10:06:27,349:INFO:epoch[0], iter[100], loss:827.520046, fps:68.49 imgs/sec, lr:0.0003258064389228821\n",
      "2022-09-20 10:07:56,619:INFO:epoch[0], iter[200], loss:88.232236, fps:71.72 imgs/sec, lr:0.0006483871256932616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2936:281473627510224,_GeneratorWorkerMp-1):2022-09-20-10:08:34.728.838 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 10000\n",
      "[WARNING] ME(1553:281468760728032,MainProcess):2022-09-20-10:08:36.597.909 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 10:09:41,072:INFO:epoch[0], iter[300], loss:56.008349, fps:61.28 imgs/sec, lr:0.0009709677542559803\n",
      "2022-09-20 10:11:29,957:INFO:epoch[1], iter[400], loss:44.020527, fps:58.78 imgs/sec, lr:0.000999938347376883\n",
      "2022-09-20 10:13:16,620:INFO:epoch[1], iter[500], loss:36.825419, fps:60.03 imgs/sec, lr:0.000999938347376883\n",
      "2022-09-20 10:15:07,191:INFO:epoch[1], iter[600], loss:33.036590, fps:57.89 imgs/sec, lr:0.000999938347376883\n",
      "2022-09-20 10:17:00,968:INFO:epoch[2], iter[700], loss:30.637895, fps:56.26 imgs/sec, lr:0.0009997532470151782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468777513440,MainProcess):2022-09-20-10:17:51.954.363 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 10:18:53,260:INFO:epoch[2], iter[800], loss:28.768294, fps:57.01 imgs/sec, lr:0.0009997532470151782\n",
      "2022-09-20 10:20:45,438:INFO:epoch[2], iter[900], loss:26.855416, fps:57.07 imgs/sec, lr:0.0009997532470151782\n",
      "2022-09-20 10:22:28,523:INFO:epoch[3], iter[1000], loss:26.020338, fps:62.10 imgs/sec, lr:0.0009994449792429805\n",
      "2022-09-20 10:24:11,982:INFO:epoch[3], iter[1100], loss:25.173995, fps:61.88 imgs/sec, lr:0.0009994449792429805\n",
      "2022-09-20 10:25:59,787:INFO:epoch[3], iter[1200], loss:23.334516, fps:59.37 imgs/sec, lr:0.0009994449792429805\n",
      "2022-09-20 10:27:45,361:INFO:epoch[4], iter[1300], loss:22.583913, fps:60.64 imgs/sec, lr:0.0009990133112296462\n",
      "2022-09-20 10:29:28,910:INFO:epoch[4], iter[1400], loss:22.355498, fps:61.82 imgs/sec, lr:0.0009990133112296462\n",
      "2022-09-20 10:31:10,366:INFO:epoch[4], iter[1500], loss:21.755259, fps:63.10 imgs/sec, lr:0.0009990133112296462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2937:281473627510224,_GeneratorWorkerMp-2):2022-09-20-10:32:31.155.061 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 10:32:54,378:INFO:epoch[5], iter[1600], loss:21.342742, fps:61.56 imgs/sec, lr:0.0009984587086364627\n",
      "2022-09-20 10:34:30,928:INFO:epoch[5], iter[1700], loss:19.874972, fps:66.30 imgs/sec, lr:0.0009984587086364627\n",
      "2022-09-20 10:36:12,403:INFO:epoch[5], iter[1800], loss:19.054879, fps:63.08 imgs/sec, lr:0.0009984587086364627\n",
      "2022-09-20 10:37:54,580:INFO:epoch[6], iter[1900], loss:18.105585, fps:62.64 imgs/sec, lr:0.0009977809386327863\n",
      "2022-09-20 10:39:35,616:INFO:epoch[6], iter[2000], loss:17.835368, fps:63.35 imgs/sec, lr:0.0009977809386327863\n",
      "2022-09-20 10:41:18,196:INFO:epoch[6], iter[2100], loss:18.378264, fps:62.40 imgs/sec, lr:0.0009977809386327863\n",
      "2022-09-20 10:43:01,362:INFO:epoch[7], iter[2200], loss:17.577214, fps:62.07 imgs/sec, lr:0.0009969804668799043\n",
      "2022-09-20 10:44:46,546:INFO:epoch[7], iter[2300], loss:16.519074, fps:60.86 imgs/sec, lr:0.0009969804668799043\n",
      "2022-09-20 10:46:29,218:INFO:epoch[7], iter[2400], loss:15.912904, fps:62.34 imgs/sec, lr:0.0009969804668799043\n",
      "2022-09-20 10:48:06,787:INFO:epoch[8], iter[2500], loss:16.106744, fps:65.61 imgs/sec, lr:0.0009960572933778167\n",
      "2022-09-20 10:49:50,752:INFO:epoch[8], iter[2600], loss:15.673048, fps:61.58 imgs/sec, lr:0.0009960572933778167\n",
      "2022-09-20 10:51:25,435:INFO:epoch[8], iter[2700], loss:15.147046, fps:67.60 imgs/sec, lr:0.0009960572933778167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2938:281473627510224,_GeneratorWorkerMp-3):2022-09-20-10:51:48.397.152 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 10000\n",
      "[WARNING] ME(1553:281468165140960,MainProcess):2022-09-20-10:51:49.439.102 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 10:53:06,908:INFO:epoch[9], iter[2800], loss:14.825684, fps:63.08 imgs/sec, lr:0.0009950118837878108\n",
      "2022-09-20 10:54:49,199:INFO:epoch[9], iter[2900], loss:15.175616, fps:62.58 imgs/sec, lr:0.0009950118837878108\n",
      "2022-09-20 10:56:34,367:INFO:epoch[9], iter[3000], loss:14.273780, fps:60.86 imgs/sec, lr:0.0009950118837878108\n",
      "2022-09-20 10:58:11,406:INFO:epoch[10], iter[3100], loss:14.472479, fps:65.97 imgs/sec, lr:0.0009938441216945648\n",
      "2022-09-20 10:59:49,929:INFO:epoch[10], iter[3200], loss:14.289655, fps:64.97 imgs/sec, lr:0.0009938441216945648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468190319072,MainProcess):2022-09-20-11:00:04.556.81 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 11:01:31,644:INFO:epoch[10], iter[3300], loss:13.883628, fps:62.93 imgs/sec, lr:0.0009938441216945648\n",
      "2022-09-20 11:03:12,175:INFO:epoch[10], iter[3400], loss:13.722390, fps:63.67 imgs/sec, lr:0.0009938441216945648\n",
      "2022-09-20 11:04:51,569:INFO:epoch[11], iter[3500], loss:13.255777, fps:64.40 imgs/sec, lr:0.0009925547055900097\n",
      "2022-09-20 11:06:33,272:INFO:epoch[11], iter[3600], loss:12.776893, fps:62.95 imgs/sec, lr:0.0009925547055900097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468156748256,MainProcess):2022-09-20-11:07:43.525.940 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 11:08:19,945:INFO:epoch[11], iter[3700], loss:12.947203, fps:60.00 imgs/sec, lr:0.0009925547055900097\n",
      "2022-09-20 11:10:06,181:INFO:epoch[12], iter[3800], loss:13.198394, fps:60.25 imgs/sec, lr:0.0009911436354741454\n",
      "2022-09-20 11:11:50,626:INFO:epoch[12], iter[3900], loss:12.565134, fps:61.28 imgs/sec, lr:0.0009911436354741454\n",
      "2022-09-20 11:13:32,452:INFO:epoch[12], iter[4000], loss:13.112863, fps:62.86 imgs/sec, lr:0.0009911436354741454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468173533664,MainProcess):2022-09-20-11:13:53.595.209 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 11:15:10,506:INFO:epoch[13], iter[4100], loss:12.020436, fps:65.28 imgs/sec, lr:0.0009896113770082593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468198711776,MainProcess):2022-09-20-11:16:21.384.595 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 11:16:52,193:INFO:epoch[13], iter[4200], loss:12.215127, fps:62.94 imgs/sec, lr:0.0009896113770082593\n",
      "2022-09-20 11:18:38,428:INFO:epoch[13], iter[4300], loss:11.903435, fps:60.26 imgs/sec, lr:0.0009896113770082593\n",
      "2022-09-20 11:20:21,811:INFO:epoch[14], iter[4400], loss:12.418098, fps:61.92 imgs/sec, lr:0.0009879583958536386\n",
      "2022-09-20 11:22:02,791:INFO:epoch[14], iter[4500], loss:11.866977, fps:63.38 imgs/sec, lr:0.0009879583958536386\n",
      "2022-09-20 11:23:43,557:INFO:epoch[14], iter[4600], loss:11.626442, fps:63.54 imgs/sec, lr:0.0009879583958536386\n",
      "2022-09-20 11:25:25,499:INFO:epoch[15], iter[4700], loss:11.355380, fps:62.79 imgs/sec, lr:0.0009861849248409271\n",
      "2022-09-20 11:27:09,487:INFO:epoch[15], iter[4800], loss:11.550692, fps:61.55 imgs/sec, lr:0.0009861849248409271\n",
      "2022-09-20 11:28:52,947:INFO:epoch[15], iter[4900], loss:10.987218, fps:61.87 imgs/sec, lr:0.0009861849248409271\n",
      "2022-09-20 11:30:29,842:INFO:epoch[16], iter[5000], loss:11.131780, fps:66.06 imgs/sec, lr:0.0009842915460467339\n",
      "2022-09-20 11:32:08,286:INFO:epoch[16], iter[5100], loss:10.972873, fps:65.02 imgs/sec, lr:0.0009842915460467339\n",
      "2022-09-20 11:33:45,414:INFO:epoch[16], iter[5200], loss:10.758552, fps:65.90 imgs/sec, lr:0.0009842915460467339\n",
      "2022-09-20 11:35:25,838:INFO:epoch[17], iter[5300], loss:11.049281, fps:63.77 imgs/sec, lr:0.0009822787251323462\n",
      "2022-09-20 11:37:05,992:INFO:epoch[17], iter[5400], loss:10.693286, fps:63.91 imgs/sec, lr:0.0009822787251323462\n",
      "2022-09-20 11:38:47,210:INFO:epoch[17], iter[5500], loss:10.774493, fps:63.24 imgs/sec, lr:0.0009822787251323462\n",
      "2022-09-20 11:40:28,002:INFO:epoch[18], iter[5600], loss:10.916446, fps:63.52 imgs/sec, lr:0.0009801468113437295\n",
      "2022-09-20 11:42:10,368:INFO:epoch[18], iter[5700], loss:10.755986, fps:62.53 imgs/sec, lr:0.0009801468113437295\n",
      "2022-09-20 11:43:54,992:INFO:epoch[18], iter[5800], loss:10.741233, fps:61.18 imgs/sec, lr:0.0009801468113437295\n",
      "2022-09-20 11:45:38,565:INFO:epoch[19], iter[5900], loss:10.448857, fps:61.80 imgs/sec, lr:0.0009778965031728148\n",
      "2022-09-20 11:47:25,543:INFO:epoch[19], iter[6000], loss:9.826844, fps:59.83 imgs/sec, lr:0.0009778965031728148\n",
      "2022-09-20 11:49:07,596:INFO:epoch[19], iter[6100], loss:10.218942, fps:62.72 imgs/sec, lr:0.0009778965031728148\n",
      "2022-09-20 11:50:46,567:INFO:epoch[20], iter[6200], loss:10.441022, fps:64.67 imgs/sec, lr:0.0009755282662808895\n",
      "2022-09-20 11:52:34,596:INFO:epoch[20], iter[6300], loss:10.292950, fps:59.25 imgs/sec, lr:0.0009755282662808895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2939:281473627510224,_GeneratorWorkerMp-4):2022-09-20-11:53:17.250.791 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 10000\n",
      "[WARNING] ME(1553:281468769120736,MainProcess):2022-09-20-11:53:18.905.387 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 11:54:18,786:INFO:epoch[20], iter[6400], loss:9.550386, fps:61.43 imgs/sec, lr:0.0009755282662808895\n",
      "2022-09-20 11:55:56,710:INFO:epoch[20], iter[6500], loss:9.275749, fps:65.36 imgs/sec, lr:0.0009755282662808895\n",
      "2022-09-20 11:57:38,028:INFO:epoch[21], iter[6600], loss:9.616993, fps:63.18 imgs/sec, lr:0.0009730426827445626\n",
      "2022-09-20 11:59:24,064:INFO:epoch[21], iter[6700], loss:9.467373, fps:60.36 imgs/sec, lr:0.0009730426827445626\n",
      "2022-09-20 12:01:04,875:INFO:epoch[21], iter[6800], loss:9.421648, fps:63.49 imgs/sec, lr:0.0009730426827445626\n",
      "2022-09-20 12:02:42,376:INFO:epoch[22], iter[6900], loss:9.296675, fps:65.65 imgs/sec, lr:0.0009704403928481042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468752335328,MainProcess):2022-09-20-12:04:04.419.420 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 12:04:28,076:INFO:epoch[22], iter[7000], loss:9.301019, fps:60.57 imgs/sec, lr:0.0009704403928481042\n",
      "2022-09-20 12:06:16,576:INFO:epoch[22], iter[7100], loss:9.441888, fps:59.00 imgs/sec, lr:0.0009704403928481042\n",
      "2022-09-20 12:08:03,558:INFO:epoch[23], iter[7200], loss:9.159651, fps:59.84 imgs/sec, lr:0.0009677220368757844\n",
      "2022-09-20 12:09:40,567:INFO:epoch[23], iter[7300], loss:9.599886, fps:65.99 imgs/sec, lr:0.0009677220368757844\n",
      "2022-09-20 12:11:23,471:INFO:epoch[23], iter[7400], loss:9.491762, fps:62.21 imgs/sec, lr:0.0009677220368757844\n",
      "2022-09-20 12:13:06,860:INFO:epoch[24], iter[7500], loss:9.091850, fps:61.92 imgs/sec, lr:0.0009648882551118731\n",
      "2022-09-20 12:14:47,589:INFO:epoch[24], iter[7600], loss:8.817103, fps:63.55 imgs/sec, lr:0.0009648882551118731\n",
      "2022-09-20 12:16:31,785:INFO:epoch[24], iter[7700], loss:8.830323, fps:61.43 imgs/sec, lr:0.0009648882551118731\n",
      "2022-09-20 12:18:15,460:INFO:epoch[25], iter[7800], loss:8.967200, fps:61.74 imgs/sec, lr:0.0009619397460483015\n",
      "2022-09-20 12:19:59,759:INFO:epoch[25], iter[7900], loss:8.579225, fps:61.37 imgs/sec, lr:0.0009619397460483015\n",
      "2022-09-20 12:21:43,188:INFO:epoch[25], iter[8000], loss:8.610144, fps:61.88 imgs/sec, lr:0.0009619397460483015\n",
      "2022-09-20 12:23:23,274:INFO:epoch[26], iter[8100], loss:8.662358, fps:63.96 imgs/sec, lr:0.0009588773245923221\n",
      "2022-09-20 12:25:08,314:INFO:epoch[26], iter[8200], loss:8.747327, fps:60.93 imgs/sec, lr:0.0009588773245923221\n",
      "2022-09-20 12:26:52,152:INFO:epoch[26], iter[8300], loss:8.562267, fps:61.64 imgs/sec, lr:0.0009588773245923221\n",
      "2022-09-20 12:28:37,952:INFO:epoch[27], iter[8400], loss:8.441356, fps:60.51 imgs/sec, lr:0.0009557016310282052\n",
      "2022-09-20 12:30:18,080:INFO:epoch[27], iter[8500], loss:8.569160, fps:63.95 imgs/sec, lr:0.0009557016310282052\n",
      "2022-09-20 12:31:58,537:INFO:epoch[27], iter[8600], loss:8.921713, fps:63.72 imgs/sec, lr:0.0009557016310282052\n",
      "2022-09-20 12:33:45,165:INFO:epoch[28], iter[8700], loss:8.632323, fps:60.03 imgs/sec, lr:0.0009524135384708643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(1553:281468794298848,MainProcess):2022-09-20-12:34:08.282.809 [mindspore/dataset/engine/queue.py:108] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 16777216 current rowsize 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-20 12:35:28,450:INFO:epoch[28], iter[8800], loss:8.693801, fps:61.99 imgs/sec, lr:0.0009524135384708643\n",
      "2022-09-20 12:37:13,638:INFO:epoch[28], iter[8900], loss:8.807833, fps:60.85 imgs/sec, lr:0.0009524135384708643\n",
      "2022-09-20 12:38:54,670:INFO:epoch[29], iter[9000], loss:8.261140, fps:63.36 imgs/sec, lr:0.0009490138036198914\n",
      "2022-09-20 12:40:38,190:INFO:epoch[29], iter[9100], loss:8.150254, fps:61.84 imgs/sec, lr:0.0009490138036198914\n",
      "2022-09-20 12:42:21,159:INFO:epoch[29], iter[9200], loss:8.197369, fps:62.16 imgs/sec, lr:0.0009490138036198914\n",
      "2022-09-20 12:44:04,960:INFO:epoch[30], iter[9300], loss:8.088545, fps:61.66 imgs/sec, lr:0.0009455032413825393\n",
      "2022-09-20 12:45:47,999:INFO:epoch[30], iter[9400], loss:7.831754, fps:62.13 imgs/sec, lr:0.0009455032413825393\n",
      "2022-09-20 12:47:32,501:INFO:epoch[30], iter[9500], loss:8.109892, fps:61.26 imgs/sec, lr:0.0009455032413825393\n",
      "2022-09-20 12:49:17,410:INFO:epoch[30], iter[9600], loss:8.026987, fps:61.02 imgs/sec, lr:0.0009455032413825393\n",
      "2022-09-20 12:50:59,969:INFO:epoch[31], iter[9700], loss:8.159601, fps:62.41 imgs/sec, lr:0.0009418828412890434\n",
      "2022-09-20 12:52:42,632:INFO:epoch[31], iter[9800], loss:7.874273, fps:62.34 imgs/sec, lr:0.0009418828412890434\n",
      "2022-09-20 12:54:20,318:INFO:epoch[31], iter[9900], loss:7.920735, fps:65.53 imgs/sec, lr:0.0009418828412890434\n",
      "2022-09-20 12:56:07,198:INFO:epoch[32], iter[10000], loss:7.356461, fps:59.90 imgs/sec, lr:0.0009381533600389957\n",
      "2022-09-20 12:57:52,064:INFO:epoch[32], iter[10100], loss:7.840042, fps:61.05 imgs/sec, lr:0.0009381533600389957\n",
      "2022-09-20 12:59:35,259:INFO:epoch[32], iter[10200], loss:7.820173, fps:62.02 imgs/sec, lr:0.0009381533600389957\n",
      "2022-09-20 13:01:14,507:INFO:epoch[33], iter[10300], loss:7.701362, fps:64.49 imgs/sec, lr:0.0009343157289549708\n",
      "2022-09-20 13:02:55,102:INFO:epoch[33], iter[10400], loss:7.291203, fps:63.63 imgs/sec, lr:0.0009343157289549708\n",
      "2022-09-20 13:04:42,600:INFO:epoch[33], iter[10500], loss:7.899929, fps:59.55 imgs/sec, lr:0.0009343157289549708\n",
      "2022-09-20 13:06:34,000:INFO:epoch[34], iter[10600], loss:7.763631, fps:57.47 imgs/sec, lr:0.0009303709957748652\n",
      "2022-09-20 13:08:23,654:INFO:epoch[34], iter[10700], loss:7.723247, fps:58.37 imgs/sec, lr:0.0009303709957748652\n",
      "2022-09-20 13:10:12,266:INFO:epoch[34], iter[10800], loss:7.590854, fps:58.95 imgs/sec, lr:0.0009303709957748652\n",
      "2022-09-20 13:11:58,204:INFO:epoch[35], iter[10900], loss:7.459086, fps:60.43 imgs/sec, lr:0.0009263200918212533\n",
      "2022-09-20 13:13:47,544:INFO:epoch[35], iter[11000], loss:7.813615, fps:58.54 imgs/sec, lr:0.0009263200918212533\n",
      "2022-09-20 13:15:24,493:INFO:epoch[35], iter[11100], loss:7.536969, fps:66.02 imgs/sec, lr:0.0009263200918212533\n",
      "2022-09-20 13:17:05,844:INFO:epoch[36], iter[11200], loss:7.474840, fps:63.15 imgs/sec, lr:0.0009221639484167099\n",
      "2022-09-20 13:18:44,182:INFO:epoch[36], iter[11300], loss:7.331679, fps:65.11 imgs/sec, lr:0.0009221639484167099\n",
      "2022-09-20 13:20:16,907:INFO:epoch[36], iter[11400], loss:7.326067, fps:69.03 imgs/sec, lr:0.0009221639484167099\n",
      "2022-09-20 13:21:54,897:INFO:epoch[37], iter[11500], loss:8.273410, fps:65.33 imgs/sec, lr:0.0009179036715067923\n",
      "2022-09-20 13:23:34,079:INFO:epoch[37], iter[11600], loss:7.313533, fps:64.54 imgs/sec, lr:0.0009179036715067923\n",
      "2022-09-20 13:25:14,157:INFO:epoch[37], iter[11700], loss:7.879370, fps:63.97 imgs/sec, lr:0.0009179036715067923\n",
      "2022-09-20 13:26:46,615:INFO:epoch[38], iter[11800], loss:6.943682, fps:69.24 imgs/sec, lr:0.000913540308829397\n",
      "2022-09-20 13:28:33,543:INFO:epoch[38], iter[11900], loss:7.228818, fps:59.86 imgs/sec, lr:0.000913540308829397\n",
      "2022-09-20 13:30:18,328:INFO:epoch[38], iter[12000], loss:7.566172, fps:61.09 imgs/sec, lr:0.000913540308829397\n",
      "2022-09-20 13:31:57,934:INFO:epoch[39], iter[12100], loss:7.210238, fps:64.27 imgs/sec, lr:0.0009090748499147594\n",
      "2022-09-20 13:33:31,124:INFO:epoch[39], iter[12200], loss:7.406339, fps:68.68 imgs/sec, lr:0.0009090748499147594\n",
      "2022-09-20 13:35:15,883:INFO:epoch[39], iter[12300], loss:7.050538, fps:61.11 imgs/sec, lr:0.0009090748499147594\n",
      "2022-09-20 13:36:58,499:INFO:epoch[40], iter[12400], loss:7.208792, fps:62.38 imgs/sec, lr:0.0009045085171237588\n",
      "2022-09-20 13:38:33,197:INFO:epoch[40], iter[12500], loss:7.180232, fps:67.60 imgs/sec, lr:0.0009045085171237588\n",
      "2022-09-20 13:40:11,858:INFO:epoch[40], iter[12600], loss:6.927746, fps:64.89 imgs/sec, lr:0.0009045085171237588\n",
      "2022-09-20 13:41:43,836:INFO:epoch[40], iter[12700], loss:6.661285, fps:69.60 imgs/sec, lr:0.0009045085171237588\n",
      "2022-09-20 13:43:12,819:INFO:epoch[41], iter[12800], loss:7.132490, fps:71.93 imgs/sec, lr:0.0008998423581942916\n",
      "2022-09-20 13:44:43,380:INFO:epoch[41], iter[12900], loss:6.936139, fps:70.69 imgs/sec, lr:0.0008998423581942916\n",
      "2022-09-20 13:46:13,284:INFO:epoch[41], iter[13000], loss:6.722815, fps:71.19 imgs/sec, lr:0.0008998423581942916\n",
      "2022-09-20 13:47:48,192:INFO:epoch[42], iter[13100], loss:6.940203, fps:67.45 imgs/sec, lr:0.0008950774790719151\n",
      "2022-09-20 13:49:21,019:INFO:epoch[42], iter[13200], loss:6.854232, fps:68.96 imgs/sec, lr:0.0008950774790719151\n",
      "2022-09-20 13:50:56,624:INFO:epoch[42], iter[13300], loss:6.789872, fps:66.95 imgs/sec, lr:0.0008950774790719151\n",
      "2022-09-20 13:52:32,520:INFO:epoch[43], iter[13400], loss:6.768894, fps:66.75 imgs/sec, lr:0.0008902152185328305\n",
      "2022-09-20 13:54:07,982:INFO:epoch[43], iter[13500], loss:6.904246, fps:67.07 imgs/sec, lr:0.0008902152185328305\n",
      "2022-09-20 13:55:46,844:INFO:epoch[43], iter[13600], loss:6.893739, fps:64.76 imgs/sec, lr:0.0008902152185328305\n",
      "2022-09-20 13:57:25,803:INFO:epoch[44], iter[13700], loss:6.863314, fps:64.70 imgs/sec, lr:0.000885256624314934\n",
      "2022-09-20 13:59:00,059:INFO:epoch[44], iter[13800], loss:6.710846, fps:67.92 imgs/sec, lr:0.000885256624314934\n",
      "2022-09-20 14:00:44,061:INFO:epoch[44], iter[13900], loss:6.583127, fps:61.55 imgs/sec, lr:0.000885256624314934\n",
      "2022-09-20 14:02:19,567:INFO:epoch[45], iter[14000], loss:6.558764, fps:67.03 imgs/sec, lr:0.0008802029769867659\n",
      "2022-09-20 14:03:54,228:INFO:epoch[45], iter[14100], loss:7.176938, fps:67.62 imgs/sec, lr:0.0008802029769867659\n",
      "2022-09-20 14:05:26,387:INFO:epoch[45], iter[14200], loss:6.589193, fps:69.45 imgs/sec, lr:0.0008802029769867659\n",
      "2022-09-20 14:06:58,589:INFO:epoch[46], iter[14300], loss:6.676894, fps:69.43 imgs/sec, lr:0.0008750555571168661\n",
      "2022-09-20 14:08:30,284:INFO:epoch[46], iter[14400], loss:6.668541, fps:69.82 imgs/sec, lr:0.0008750555571168661\n",
      "2022-09-20 14:10:04,682:INFO:epoch[46], iter[14500], loss:6.411210, fps:67.83 imgs/sec, lr:0.0008750555571168661\n",
      "2022-09-20 14:11:46,560:INFO:epoch[47], iter[14600], loss:6.842255, fps:62.83 imgs/sec, lr:0.000869815528858453\n",
      "2022-09-20 14:13:24,991:INFO:epoch[47], iter[14700], loss:6.408574, fps:65.03 imgs/sec, lr:0.000869815528858453\n",
      "2022-09-20 14:15:02,295:INFO:epoch[47], iter[14800], loss:6.354294, fps:65.80 imgs/sec, lr:0.000869815528858453\n",
      "2022-09-20 14:16:45,387:INFO:epoch[48], iter[14900], loss:6.364137, fps:62.11 imgs/sec, lr:0.0008644842891953886\n",
      "2022-09-20 14:18:33,488:INFO:epoch[48], iter[15000], loss:50.662633, fps:59.21 imgs/sec, lr:0.0008644842891953886\n",
      "2022-09-20 14:20:14,807:INFO:epoch[48], iter[15100], loss:44.274704, fps:63.17 imgs/sec, lr:0.0008644842891953886\n",
      "2022-09-20 14:21:55,263:INFO:epoch[49], iter[15200], loss:34.112277, fps:63.72 imgs/sec, lr:0.0008590631769038737\n",
      "2022-09-20 14:23:34,908:INFO:epoch[49], iter[15300], loss:29.644290, fps:64.24 imgs/sec, lr:0.0008590631769038737\n",
      "2022-09-20 14:25:03,777:INFO:epoch[49], iter[15400], loss:27.846971, fps:72.02 imgs/sec, lr:0.0008590631769038737\n",
      "2022-09-20 14:26:35,655:INFO:epoch[50], iter[15500], loss:23.530809, fps:69.68 imgs/sec, lr:0.0008535534143447876\n",
      "2022-09-20 14:28:09,222:INFO:epoch[50], iter[15600], loss:21.407161, fps:68.42 imgs/sec, lr:0.0008535534143447876\n"
     ]
    }
   ],
   "source": [
    "cloud_args=None\n",
    "args = parse_args(cloud_args)\n",
    "loss_meter = AverageMeter('loss')\n",
    "\n",
    "context.reset_auto_parallel_context()\n",
    "parallel_mode = ParallelMode.STAND_ALONE\n",
    "degree = 1\n",
    "if args.is_distributed:\n",
    "    parallel_mode = ParallelMode.DATA_PARALLEL\n",
    "    degree = get_group_size()\n",
    "context.set_auto_parallel_context(parallel_mode=parallel_mode, gradients_mean=True, device_num=degree)\n",
    "\n",
    "network = YOLOV5s(is_training=True)\n",
    "# default is kaiming-normal\n",
    "default_recurisive_init(network)\n",
    "load_yolov5_params(args, network)\n",
    "\n",
    "network = YoloWithLossCell(network)\n",
    "config = ConfigYOLOV5()\n",
    "\n",
    "config.label_smooth = args.label_smooth\n",
    "config.label_smooth_factor = args.label_smooth_factor\n",
    "\n",
    "if args.training_shape:\n",
    "    config.multi_scale = [convert_training_shape(args.training_shape)]\n",
    "if args.resize_rate:\n",
    "    config.resize_rate = args.resize_rate\n",
    "\n",
    "ds, data_size = create_yolo_dataset(image_dir=args.data_root, anno_path=args.annFile, is_training=True,\n",
    "                                    batch_size=args.per_batch_size, max_epoch=args.max_epoch,\n",
    "                                    device_num=args.group_size, rank=args.rank, config=config)\n",
    "args.logger.info('Finish loading dataset')\n",
    "\n",
    "args.steps_per_epoch = int(data_size / args.per_batch_size / args.group_size)\n",
    "\n",
    "if not args.ckpt_interval:\n",
    "    args.ckpt_interval = args.steps_per_epoch\n",
    "\n",
    "lr = get_lr(args)\n",
    "\n",
    "opt = Momentum(params=get_param_groups(network),\n",
    "               learning_rate=Tensor(lr),\n",
    "               momentum=args.momentum,\n",
    "               weight_decay=args.weight_decay,\n",
    "               loss_scale=args.loss_scale)\n",
    "\n",
    "network = TrainingWrapper(network, opt, args.loss_scale // 2)\n",
    "network.set_train()\n",
    "\n",
    "if args.rank_save_ckpt_flag:\n",
    "    # checkpoint save\n",
    "    ckpt_max_num = args.max_epoch * args.steps_per_epoch // args.ckpt_interval\n",
    "    ckpt_config = CheckpointConfig(save_checkpoint_steps=args.ckpt_interval,\n",
    "                                   keep_checkpoint_max=ckpt_max_num)\n",
    "    save_ckpt_path = os.path.join(args.outputs_dir, 'ckpt_' + str(args.rank) + '/')\n",
    "    ckpt_cb = ModelCheckpoint(config=ckpt_config,\n",
    "                              directory=save_ckpt_path,\n",
    "                              prefix='{}'.format(args.rank))\n",
    "    cb_params = _InternalCallbackParam()\n",
    "    cb_params.train_network = network\n",
    "    cb_params.epoch_num = ckpt_max_num\n",
    "    cb_params.cur_epoch_num = 1\n",
    "    run_context = RunContext(cb_params)\n",
    "    ckpt_cb.begin(run_context)\n",
    "\n",
    "old_progress = -1\n",
    "t_end = time.time()\n",
    "data_loader = ds.create_dict_iterator(output_numpy=True, num_epochs=1)\n",
    "\n",
    "for i, data in enumerate(data_loader):\n",
    "    images = data[\"image\"]\n",
    "    input_shape = images.shape[2:4]\n",
    "    images = Tensor.from_numpy(images)\n",
    "    batch_y_true_0 = Tensor.from_numpy(data['bbox1'])\n",
    "    batch_y_true_1 = Tensor.from_numpy(data['bbox2'])\n",
    "    batch_y_true_2 = Tensor.from_numpy(data['bbox3'])\n",
    "    batch_gt_box0 = Tensor.from_numpy(data['gt_box1'])\n",
    "    batch_gt_box1 = Tensor.from_numpy(data['gt_box2'])\n",
    "    batch_gt_box2 = Tensor.from_numpy(data['gt_box3'])\n",
    "    input_shape = Tensor(tuple(input_shape[::-1]), ms.float32)\n",
    "    loss = network(images, batch_y_true_0, batch_y_true_1, batch_y_true_2, batch_gt_box0, batch_gt_box1,\n",
    "                   batch_gt_box2, input_shape)\n",
    "    loss_meter.update(loss.asnumpy())\n",
    "\n",
    "    if args.rank_save_ckpt_flag:\n",
    "        # ckpt progress\n",
    "        cb_params.cur_step_num = i + 1  # current step number\n",
    "        cb_params.batch_num = i + 2\n",
    "        ckpt_cb.step_end(run_context)\n",
    "\n",
    "    if i % args.log_interval == 0:\n",
    "        time_used = time.time() - t_end\n",
    "        epoch = int(i / args.steps_per_epoch)\n",
    "        fps = args.per_batch_size * (i - old_progress) * args.group_size / time_used\n",
    "        if args.rank == 0:\n",
    "            args.logger.info(\n",
    "                'epoch[{}], iter[{}], {}, fps:{:.2f} imgs/sec, lr:{}'.format(epoch, i, loss_meter, fps, lr[i]))\n",
    "        t_end = time.time()\n",
    "        loss_meter.reset()\n",
    "        old_progress = i\n",
    "\n",
    "    if (i + 1) % args.steps_per_epoch == 0 and args.rank_save_ckpt_flag:\n",
    "        cb_params.cur_epoch_num += 1\n",
    "\n",
    "args.logger.info('==========end training===============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e058b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
